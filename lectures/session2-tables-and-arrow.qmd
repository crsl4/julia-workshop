---
title: "Session 2: Data Tables and Arrow files"
author: "Claudia Solis-Lemus and Douglas Bates"
subtitle: "ISMB 2022 Madison"
format:
  revealjs:
    incremental: true
    scrollable: true
    theme: sky
---

# Exploring Julia packages {.smaller}

- [JuliaHub](https://juliahub.com) provides a [package explorer](https://juliahub.com/ui/Packages)
- You can search by topic or a fuzzy search on names
- Sort order is by number of stars for the github repository
- Almost all packages are github repositories (some in gitlab)
- Almost all use an MIT license
- Various github groups manage packages for specific fields, such as `JuliaData` for Data Science packages
- If you check the source repository for many packages, even advanced packages, you will often see that they are 100% Julia code

# Using quarto

- These slides were created using [quarto.org](https://quarto.org)
    + an Open-Source technical writing system based on `pandoc`
    + from RStudio but not dependent on R or RStudio
    + uses [Jupyter](https://jupyter.org) kernels for evaluation of Python or Julia code

::: {.nonincremental}
## Installing packages
```{julia}
#| echo: true
#| output: false
using Pkg
Pkg.activate(joinpath("..", @__DIR__)) # use ../Project.toml
Pkg.add("Tables")     # row- or column-oriented tables
Pkg.add("Arrow")      # read and write https://arrow.apache.org format
Pkg.add("CSV")       
Pkg.add("HTTP")
Pkg.add("DataFrames") 
Pkg.add("DataFrameMacros") # elegant DataFrame manipulation
Pkg.add("Chain")      # sophisticated pipes
```

- Adding packages need only be done once per project.
- Periodically executing `using Pkg; Pkg.update()` keeps them up-to-date
:::
## Activating packages
```{julia}
#| echo: true
using Arrow, Chain, CSV, DataFrameMacros, DataFrames, HTTP, Tables
```

- We use `HTTP` and `CSV` to load data from the [ManyBabies study](https://github.com/manybabies/mb1-analysis-public/)
```{julia}
f = let
  url = "https://github.com/manybabies/mb1-analysis-public/raw/master/processed_data/02_validated_output.csv"
  CSV.File(
    HTTP.get(url).body,
    missingstring = ["NA"],
	  truestrings = ["TRUE"],
	  falsestrings = ["FALSE"],
  )
end
Tables.schema(f)
```

# Data tables in Julia


- Both `R` and `Python` (through `pandas`) use column-oriented data frames for data tables.
- Relational data bases tend to be row-oriented based on a row schema
- Of course, most data is stored in CSV files or spreadsheets
- It helps to be able to switch back and forth between these views
- The `JuliaData` group produces and maintains several packages built around a `Tables` interface

# Notebook on checking consistency

- Copy the file `notebooks/consistency.jmd` from this repository to the `notebooks` directory of your `DrWatson` project.
- This is a `Julia markdown` file, similar to `R markdown` (.Rmd)
- In your project's `notebooks` directory run

```julia
julia> pwd()
"/home/bates/projects/DataScienceWorkshop/notebooks"

julia> using DrWatson

julia> @quickactivate

julia> using Weave

julia> convert_doc("consistency.jmd", "consistency.ipynb")
"consistency.ipynb"
```

# Running the Jupyter notebooks

- This produces a Jupyter notebook.  
- You can start `jupyter notebook`or `jupyter lab` as you would normally or
- You can use the IJulia package's functions

```julia
julia> using IJulia

julia> jupyterlab(dir = ".")
```

## Exercise: Part 1

**Instructions:** Download the file `processed_data/03_data_trial_main.csv` from the `mb1-analysis-public` repository on github (or clone the repository).  Read the file using Julia's CSV package and convert the table to a DataFrame.  Use `describe` to summarize the data frame.  Can you detect any problems with the data set?

**Time:** 3-5 minutes.

Set up:
```julia
julia> using DrWatson

julia> @quickactivate

julia> using CSV, DataFrames
```

# The Arrow notebook

- `Arrow.jmd` uses the Julia `Arrow` package and Python's `pyarrow` and the `arrow` package for R.
- If you are fluent in only one of `R` or `Python` you may want to skip the parts for the other language.

---

## Exercise: Part 2

**Instructions:** Clean up any problems you have encountered in the `03_data_trial_main` frame.  Write the result to an Arrow file and read it into either `R` or `Python` for further analysis.

**Time:** 5-7 minutes.
