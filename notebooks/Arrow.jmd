
# Arrow for data saving and transfer

The [Apache Arrow format](https://arrow.apache.org/) is a binary format for column-oriented tabular data.
It is supported by packages for several languages, including `R` and `Python`.

The Julia implementation, https://github.com/JuliaData/Arrow.jl, is unusual in that it is a native implementation and does not rely on the underlying C++ library used by other implementations.

In Julia Arrow is primarily used for saving and restoring data Tables and for exchanging data tables with `R` and `Python`.

### Reading an Arrow table written from Julia

Recall that in the `consistency.jl` notebook the manybabies data were written to files `02_validated_output.arrow` and `02_validated_output_compressed.arrow`

```julia
using Pkg; Pkg.status()
```

```julia
using Arrow, DataFrames, PyCall, RCall
```

The `Arrow.Table` function reads an arrow file and returns a columnar table, which can be converted to a `DataFrame` if desired.
An uncompressed arrow file is memory-mapped so reading even a very large arrow file is fast.

```julia
tbl = Arrow.Table("02_validated_output.arrow");
```

```julia
df = DataFrame(tbl);
describe(df)
```

This is essentially the same table as was written in the "consistency.ipynb" notebook.
The values in the columns are the same as in the original table.
The column types are sometimes different from but equivalent to the original columns.

```julia
typeof(tbl.subid)
```

Reading from the compressed arrow file is similar but takes a bit longer because the file must be uncompressed when reading.

```julia
tbl2 = Arrow.Table("02_validated_output_compressed.arrow");
```

### Reading an Arrow table written with R

Suppose we wish to access the `palmerpenguins::penguins` data set from `R`.

We will use some functions from the `RCall` package without much explanation.
Suffice it to say that prepending a quoted string with `R` causes it to be evaluated in an R instance.
If the string contains quote characters it should be wrapped in triple quotes.

```julia
R"suppressPackageStartupMessages(library(arrow))";
```

```julia
R"""write_feather(palmerpenguins::penguins, "penguins.arrow")"""
```

The [`palmerpenguins` package](https://allisonhorst.github.io/palmerpenguins/) contains this table.
The `arrow` package for R and the `pyarrow` Python package both refer to the arrow file format as `feather`.
Feather was an earlier file format and the arrow format is now considered version 2 of Feather.
This is just to explain why these packages use names like `write_feather`.

Now read this file as a table in Julia.

```julia
penguins = DataFrame(Arrow.Table("penguins.arrow"))
```

```julia
describe(penguins)
```

Notice that all the columns allow for missing data, even when there are no missing values in the column.
This is always the case in `R`.

Also, the numeric types will always be `Int32` or `Float64` and most data tables will contain only these types plus `String`.


That is not a problem coming from R to Julia - at most it is an inconvenience.

To read this in Python we use the `pyarrow` package through the already loaded `PyCall` package for Julia
(note that if you install `pyarrow` using `conda` it is important to specify `-c conda-forge` - otherwise you will get a badly out-of-date version).

```julia
feather = pyimport("pyarrow.feather");
```

```julia
fr = feather.read_feather("penguins.arrow")  # returns a pandas dataframe
```

A more basic method, `feather.read_table`, produces a `pyarrow.Table`.
In fact, `read_feather` simply calls `read_table` then converts the result to a pandas dataframe.
Occasionally there are problems in the conversion so it is good to know about `read_table`.

```julia
feather.read_table("penguins.arrow")   # produces a pyarrow.Table
```

## Reading an Arrow file from Julia in R or Python

Recent additions to the `arrow` package for R and the `pyarrow` package for Python have greatly expanded the flexibility of these packages.

```julia
R"library(tibble)";
```

```julia
R"""valid <- read_feather("02_validated_output.arrow"); glimpse(valid)""";
```

It is not obvious but there are some conversions necessary to read a general arrow file and create an R `data.frame` or `tibble`.

To see the form as stored in the arrow file it is convenient to use Python's `pyarrow.Table`.

```julia
feather.read_table("02_validated_output.arrow")
```

Several columns, such as `trial_num` and `stimulus_num` are returned as the default integer type, `Int64`, from `CSV.File` and these need to be converted to `Int32` in R.

```julia
R"class(valid$trial_num)"
```

```julia
R"""write_feather(valid, "02_validated_from_R.arrow")""";
```

```julia
feather.read_table("02_validated_from_R.arrow")
```

Note that there are two changes in some columns: those that were `int64` are now `int32` and there are no columns marked `not null`.
That is, all columns now allow for missing data.

In Julia we can check with

```julia
Tables.schema(Arrow.Table("02_validated_from_R.arrow"))
```

## Conversion from Int64 vectors to smaller integer types

The `Int64` or `Union{Missing,Int64}` columns in the table, `tbl`, are coded as such because the default integer type, `Int`, is equivalent to `Int64` on a 64-bit implementation of Julia.

It is possible to specify the types of the columns in the call to `CSV.File` when reading the original CSV file but doing so requires knowing the contents of the columns before reading the file.  It is usually easier to read the file with the inferred types then change later.

First, check which columns have element types of `Int64` or `Union{Missing,Int64}`.
For this it helps to use `nonmissingtype` to produce the underlying type from a column that allows for missing data.

```julia
let et = eltype(df.trial_num)
	et, nonmissingtype(et)
end
```

```julia
let et = eltype(df.stimulus_num)
	et, nonmissingtype(et)
end
```

Now we want to examine all the columns to find those whose nonmissing eltype is `Int64`.

For a dataframe `df` the `eachcol` function returns an iterator over the columns.  Wrapping this in `pairs` produces an iterator of `name, value` pairs which we can use to discover which columns are coded as `Int64`, with or without missing values.

```julia
begin
	intcols = Symbol[]
	for (n,v) in pairs(eachcol(df))
		Int64 == nonmissingtype(eltype(v)) && push!(intcols, n)
	end
	intcols
end
```

For each of these columns we determine the extrema (minimum and maximum), using `skipmissing` to avoid the missing values, then compare against the `typemin` and `typemax` for various integer types to determine the smallest type of integer that can encode the data.

```julia
function inttype(x)
	mn, mx = extrema(skipmissing(x))
	if typemin(Int8) ≤ mn ≤ mx ≤ typemax(Int8)
		Int8
	elseif typemin(Int16) ≤ mn ≤ mx ≤ typemax(Int16)
		Int16
	elseif typemin(Int32) ≤ mn ≤ mx ≤ typemax(Int32)
		Int32
	else
		Int64
	end
end
```

```julia
conv = map(sym -> Pair(sym, inttype(getproperty(df, sym))), intcols)
```

```julia
for pr in conv
	setproperty!(df, first(pr), passmissing(last(pr)).(getproperty(df, first(pr))))
end
```

There are two columns, `bilingual_parenta_nae` and `bilingual_parentb_nae`, that only contain missing values.
We can safely drop these when we write a new Arrow file.

```julia
Arrow.write("02.arrow", select(df, Not(startswith("bilingual_parent").(names(df)))), compress=:zstd)
```

```julia
filesize("02.arrow")
```

```julia
feather.read_table("02.arrow")
```
